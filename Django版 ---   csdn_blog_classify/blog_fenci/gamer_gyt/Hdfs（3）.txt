HDFS学习笔记


1.1、数据块(block)

HDFS(Hadoop Distributed File System)默认的最基本的存储单位是64M的数据块。和普通文件系统相同的是，HDFS中的文件是被分成64M一块的数据块存储的。不同于普通文件系统的是，HDFS中，如果一个文件小于一个数据块的大小，并不占用整个数据块存储空间。

1.2、元数据节点(Namenode)和数据节点(datanode)

元数据节点用来管理文件系统的命名空间

其将所有的文件和文件夹的元数据保存在一个文件系统树中。这些信息也会在硬盘上保存成以下文件：命名空间镜像(namespace image)及修改日志(edit log)其还保存了一个文件包括哪些数据块，分布在哪些数据节点上。然而这些信息并不存储在硬盘上，而是在系统启动的时候从数据节点收集而成的。
数据节点是文件系统中真正存储数据的地方。

客户端(client)或者元数据信息(namenode)可以向数据节点请求写入或者读出数据块。其周期性的向元数据节点回报其存储的数据块信息。
从元数据节点(secondary namenode)

从元数据节点并不是元数据节点出现问题时候的备用节点，它和元数据节点负责不同的事情。其主要功能就是周期性将元数据节点的命名空间镜像文件和修改日志合并，以防日志文件过大。这点在下面会相信叙述。合并过后的命名空间镜像文件也在从元数据节点保存了一份，以防元数据节点失败的时候，可以恢复。


1.2.1、元数据节点文件夹结构




VERSION文件是java properties文件，保存了HDFS的版本号。

layoutVersion是一个负整数，保存了HDFS的持续化在硬盘上的数据结构的格式版本号。namespaceID是文件系统的唯一标识符，是在文件系统初次格式化时生成的。cTime此处为0storageType表示此文件夹中保存的是元数据节点的数据结构。





namespaceID=1232737062
cTime=0
storageType=NAME_NODE
layoutVersion=-18





1.2.2、文件系统命名空间映像文件及修改日志

当文件系统客户端(client)进行写操作时，首先把它记录在修改日志中(edit log)元数据节点在内存中保存了文件系统的元数据信息。在记录了修改日志后，元数据节点则修改内存中的数据结构。每次的写操作成功之前，修改日志都会同步(sync)到文件系统。fsimage文件，也即命名空间映像文件，是内存中的元数据在硬盘上的checkpoint，它是一种序列化的格式，并不能够在硬盘上直接修改。同数据的机制相似，当元数据节点失败时，则最新checkpoint的元数据信息从fsimage加载到内存中，然后逐一重新执行修改日志中的操作。从元数据节点就是用来帮助元数据节点将内存中的元数据信息checkpoint到硬盘上的checkpoint的过程如下：

从元数据节点通知元数据节点生成新的日志文件，以后的日志都写到新的日志文件中。从元数据节点用http get从元数据节点获得fsimage文件及旧的日志文件。从元数据节点将fsimage文件加载到内存中，并执行日志文件中的操作，然后生成新的fsimage文件。从元数据节点奖新的fsimage文件用http post传回元数据节点元数据节点可以将旧的fsimage文件及旧的日志文件，换为新的fsimage文件和新的日志文件(第一步生成的)，然后更新fstime文件，写入此次checkpoint的时间。这样元数据节点中的fsimage文件保存了最新的checkpoint的元数据信息，日志文件也重新开始，不会变的很大了。





1.2.3、从元数据节点的目录结构




1.2.4、数据节点的目录结构




数据节点的VERSION文件格式如下：




namespaceID=1232737062
storageID=DS-1640411682-127.0.1.1-50010-1254997319480
cTime=0
storageType=DATA_NODE
layoutVersion=-18





blk_<id>保存的是HDFS的数据块，其中保存了具体的二进制数据。blk_<id>.meta保存的是数据块的属性信息：版本信息，类型信息，和checksum当一个目录中的数据块到达一定数量的时候，则创建子文件夹来保存数据块及数据块属性信息。

二、数据流(data flow)

2.1、读文件的过程

客户端(client)用FileSystem的open()函数打开文件DistributedFileSystem用RPC调用元数据节点，得到文件的数据块信息。对于每一个数据块，元数据节点返回保存数据块的数据节点的地址。DistributedFileSystem返回FSDataInputStream给客户端，用来读取数据。客户端调用stream的read()函数开始读取数据。DFSInputStream连接保存此文件第一个数据块的最近的数据节点。Data从数据节点读到客户端(client)当此数据块读取完毕时，DFSInputStream关闭和此数据节点的连接，然后连接此文件下一个数据块的最近的数据节点。当客户端读取完毕数据的时候，调用FSDataInputStream的close函数。在读取数据的过程中，如果客户端在与数据节点通信出现错误，则尝试连接包含此数据块的下一个数据节点。失败的数据节点将被记录，以后不再连接。




2.2、写文件的过程

客户端调用create()来创建文件DistributedFileSystem用RPC调用元数据节点，在文件系统的命名空间中创建一个新的文件。元数据节点首先确定文件原来不存在，并且客户端有创建文件的权限，然后创建新文件。DistributedFileSystem返回DFSOutputStream，客户端用于写数据。客户端开始写入数据，DFSOutputStream将数据分成块，写入data queue。Data queue由Data Streamer读取，并通知元数据节点分配数据节点，用来存储数据块(每块默认复制3块)。分配的数据节点放在一个pipeline里。Data Streamer将数据块写入pipeline中的第一个数据节点。第一个数据节点将数据块发送给第二个数据节点。第二个数据节点将数据发送给第三个数据节点。DFSOutputStream为发出去的数据块保存了ack queue，等待pipeline中的数据节点告知数据已经写入成功。如果数据节点在写入的过程中失败：

关闭pipeline，将ack queue中的数据块放入data queue的开始。当前的数据块在已经写入的数据节点中被元数据节点赋予新的标示，则错误节点重启后能够察觉其数据块是过时的，会被删除。失败的数据节点从pipeline中移除，另外的数据块则写入pipeline中的另外两个数据节点。元数据节点则被通知此数据块是复制块数不足，将来会再创建第三份备份。
当客户端结束写入数据，则调用stream的close函数。此操作将所有的数据块写入pipeline中的数据节点，并等待ack queue返回成功。最后通知元数据节点写入完毕。




HDFS Federation(HDFS 联邦)（Hadoop2.3）


最早接触Federation这个词还是第一家公司用的DB2联邦数据库。

第一代Hadoop HDFS：




 

结构上由一个namenode和众多datanode组成。

功能上划分为namespace和block storage service 两部分。

 

所谓的HDFS Federation就是有多个namenode（或者说namespace）。

如图：




 

这里有block pool的概念，每一个namespace都有一个pool，datanodes会存储集群中所有的pool，block pool之间的管理是独立的，一个namespace生成一个block id时不需要跟其它namespace协调，一个namenode的失败也不会影响到datanode对其它namenodes的服务。

一个namespace和它的blockpool作为一个管理单元，删除后，对应于datanodes中的pool也会被删除。集群升级时，这个管理单元也独立升级。

这里引入clusterID来标示集群所有节点。当一个namenode format之后，这个id生成，集群中其它namenode的format也用这个id。

多namenode的好处：

1、namespace可扩展性。原来只有hdfs存储可以水平扩展，现在namenode也可以做到了，减轻单namenode的内存和服务压力。

2、性能方面。多个namenode可以提高读写时的吞吐量。

3、隔离性。隔离不同类型的程序，一定程度上控制资源的分配。

联邦的配置：

联邦的配置是向后兼容的，允许在不改变任何配置的情况下让当前运行的单节点环境转换成联邦环境。新的配置方案确保了在集群环境中的所有节点的配置文件都是相同的。

这里引入了NameServiceID概念，作为namenodes们的后缀。

第一步：配置属性dfs.nameservices，用于datanodes们识别namenodes。

第二步：为每个namenode加入这个后缀。

例子：

 
<configuration>
  <property>
    <name>dfs.nameservices</name>
    <value>ns1,ns2</value>
  </property>
  <property>
    <name>dfs.namenode.rpc-address.ns1</name>
    <value>nn-host1:rpc-port</value>
  </property>
  <property>
    <name>dfs.namenode.http-address.ns1</name>
    <value>nn-host1:http-port</value>
  </property>
  <property>
    <name>dfs.namenode.secondaryhttp-address.ns1</name>
    <value>snn-host1:http-port</value>
  </property>
  <property>
    <name>dfs.namenode.rpc-address.ns2</name>
    <value>nn-host2:rpc-port</value>
  </property>
  <property>
    <name>dfs.namenode.http-address.ns2</name>
    <value>nn-host2:http-port</value>
  </property>
  <property>
    <name>dfs.namenode.secondaryhttp-address.ns2</name>
    <value>snn-host2:http-port</value>
  </property>

  .... Other common configuration ...
</configuration>

 

 

管理集群：

启动和停止用start-dfs.sh和stop-dfs.sh

跟第一代hadoop不同的是：这里允许集群中任何一台有效节点运行这两个命令，根据配置启动namenode和datanode，而第一代hadoop则是以运行启动脚本的节点为单一namenode。

均衡器:

由于多namenode了，均衡器也做了改变，运行命令：

 
"$HADOOP_PREFIX"/bin/hadoop-daemon.sh --config $HADOOP_CONF_DIR --script "$bin"/hdfs start balancer [-policy <policy>]

策略可以是node，之前也有的，增加了block pool，既在datanode级别又在block pool级别均衡。

下线节点：

跟之前版本的类似，把需要下线的节点添加到每台namenode的exclude文件中。

第一步:
"$HADOOP_PREFIX"/bin/distributed-exclude.sh <exclude_file>
第二步：
"$HADOOP_PREFIX"/bin/refresh-namenodes.sh
 
集群控制台：
 
http://<any_nn_host:port>/dfsclusterhealth.jsp

hdfs之快照的学习


 HDFS快照是文件系统的只读的实时的拷贝，可以是文件系统的一部分或者整个文件系统。快照的一些通用场景是数据备份，对用户错误的保护和灾难恢复。HDFS的快照实现是高效的：



快照的创建时瞬间完成的，排除查找inode的时间，需要花费O(1)，即常数时间。只有执行与快照相关的修改时才需要额外的内存，内存开销为O(M)，M为修改的文件或者目录的数量。DataNodes中的块不会被复制，快照文件只记录块列表和文件的大小，没有数据的复制。快照对常规HDFS操作没有有害影响，修改按时间逆序记录这样当前数据可以直接被访问（因为当前数据排在最前面，逆序）。快照数据通过从当前数据中减去修改来计算。



      只要目录被设置为使用快照，快照就可以作用在目录上，一个启用快照的目录能够同时容纳65536个快照，对于能够启用快照的目录数量不做限制，管理员或许会将每个目录设置为启用快照。如果在启用快照的目录中存在快照，该目录在所有的快照删除之前既不可以被删除也不可以重命名。嵌套启用快照的目录目前是不支持的。换句话说如果一个目录的祖先或者后代是启用快照的目录，那么该目录是不能设置为启用快照的。

      对于启用快照的目录，路径中.snapshot用于访问它的快照。假设/foo是快照目录，/foo/bar是/foo中的一个文件或者目录，/foo有一个快照s0，那么路径/foo/.snapshot/s0/bar引用/foo/bar的快照。通常使用的HDFS API和CLI都可以使用.snapshot路径访问快照，例如：







hdfs dfs -ls /foo/.snapshot                          列出快照目录下的所有快照  
hdfs dfs -ls /foo/.snapshot/s0                        列出快照s0下的文件  
hdfs dfs -cp -ptopax /foo/.snapshot/s0/bar /tmp         从快照s0拷贝文件bar到/tmp  





最后一个例子使用了保持选项-ptopax以保持原有的时间戳（t），拥有者（o），权限（p），访问控制列表（a）和XAttrs（x）。
在学习了HDFS快照的基本概念和特点后，接下来要实际执行一些与快照相关的操作，比如启用快照，禁用快照，创建快照等，下面分别进行学习。要启用快照或者禁用快照必须具备超级用户的权限，启用快照的命令如下，如果该命令执行成功则相应目录启用了快照，其中path为需要启用快照的目录。





[java] view
 plaincopyprint?






hdfs dfsadmin -allowSnapshot <snapshotDir>  




      假设将test目录设置为启用快照，执行的命令及输出结果如下，此时仅仅是对test目录启用了快照，并为创建快照文件。



[java] view
 plaincopyprint?






[hadoop@hadoop ~]$ hdfs dfsadmin -allowSnapshot test/  
Allowing snaphot on test/ succeeded  


      在禁用某个目录的快照之前，需要删除该目录的所有快照，禁用快照的命令为：





[java] view
 plaincopyprint?






hdfs dfsadmin -disallowSnapshot <snapshotDir>  
  
[hadoop@hadoop ~]$ hdfs dfsadmin -disallowSnapshot test  
Disallowing snaphot on test succeeded  




      下面为创建快照、删除快照等操作，这些操作普通用户可以执行，但必须满足这些操作的权限要求，而超级用户可执行下面的所有命令且不用满足权限要求。首先是创建快照的命令，该操作要求用户必须是启用快照的目录的拥有者，命令及演示效果为：





[java] view
 plaincopyprint?






hdfs dfs -createSnapshot <snapshotDir> [<snapshotName>]  
  
[hadoop@hadoop ~]$ hdfs dfs -createSnapshot test  
Created snapshot /user/hadoop/test/.snapshot/s20141023-111821.944  
[hadoop@hadoop ~]$ hdfs dfs -ls test/.snapshot  
drwxr-xr-x   - hadoop supergroup  0 2014-10-23 11:18 test/.snapshot/s20141023-111821.944  




      该命令的第二个参数为快照的名称，若未指定则系统将生成以字符s开头紧跟当前时间戳的名称，如上面的s20141023-111821.944。

      可以对快照重命名，该操作要求用户拥有快照目录的所有者权限，该命令如下及执行结果如下所示，需要注意的是命令中的oldName或者newName仅为快照的文件名，而不包含.snapshot部分。



[java] view
 plaincopyprint?






hdfs dfs -renameSnapshot <snapshotDir> <oldName> <newName>  
  
[hadoop@hadoop ~]$ hdfs dfs -renameSnapshot test/ s20141023-111821.944 snapshot01  
[hadoop@hadoop ~]$ hdfs dfs -ls test/.snapshot/  
Found 1 items  
drwxr-xr-x   - hadoop supergroup          0 2014-10-23 11:18 test/.snapshot/snapshot01  


      可以使用下面的命令获取当前用户有权限创建快照的所有快照目录，注意获取的是所有已经启用快照的目录。



[java] view
 plaincopyprint?






[hadoop@hadoop ~]$ hdfs lsSnapshottableDir  
drwxr-xr-x 0 hadoop supergroup 0 2014-10-23 11:18 1 65536 /user/hadoop/test  


      下面的命令用于删除快照，该命令也要求用户具有快照目录的所有者权限：



[java] view
 plaincopyprint?






hdfs dfs -deleteSnapshot <snapshotDir> <snapshotName>  
  
[hadoop@hadoop ~]$ hdfs dfs -deleteSnapshot test/ snapshot01 


hadoop命令——hdfs

hdfs是hadoop大体系下的分布式文件管理系统，是英文Hadoop Distributed File System的简写，其常用命令如下：
一：fs命令（和Linux终端运行命令一致，也是hdfs最常用命令）



二：其他相关命令
1、hadoop 归档文件shell： hadoop archive -archiveName file.har -p /gyt/input /gyt/output (file.har为归档后的文件  /gyt/inut/为多个文件所在目录   /gyt/output/是归档后的输出目录)
2、运行JAR程序包shell：hadoop jar /home/hadoop/hadoop-1.1.2/hadoop-examples-1.1.2.jar wordcount  /user/hadoop/input output（XXX.jar是程序目录，wordcount是程序入口，XXX/input是文件输入源，output是文件输出源）
4、查看HDFS状态：hadoop dfsadmin -report比如有哪些datanode，每个datanode的情况
5、离开安全模式：hadoop dfsadmin -safemode leave 

6、进入安全模式： hadoop dfsadmin -safemode enter


......


参考：http://blog.sina.com.cn/s/blog_3fe961ae0101ftyt.html
          http://blog.csdn.net/kuanghongjiang/article/details/24476777


